{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614a7657",
   "metadata": {},
   "source": [
    "### Statistics vs. machine learning\n",
    "\n",
    "- Statistics: Summarizing and fitting the (all your) data\n",
    "\n",
    "- Machine learning: Making predictions on (new held-out) data \n",
    "\n",
    "### When to use a classifier vs. deep learning\n",
    "- Classifier: For smaller or lower-dimensional data. Works with fewer samples.\n",
    "\n",
    "- Deep learning: Large or high-dimensional data (e.g., images, text). Requires more samples. Generally slower to train, but more accurate/flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d95d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "project_name = 'vlad-lab'\n",
    "import os\n",
    "#get current working directory\n",
    "cwd = os.getcwd()\n",
    "git_dir = cwd.split(project_name)[0] + project_name\n",
    "import sys\n",
    "sys.path.append(git_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "\n",
    "import pdb\n",
    "import scipy.stats as stats\n",
    "from glob import glob as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5924b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_acts(acts_dir):\n",
    "    \"\"\"\n",
    "    Concatenate activation files from a directory and extract labels from filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    acts_dir (str): Directory containing activation .npy files.\n",
    "    \n",
    "    Returns:\n",
    "    all_acts (np.ndarray): Concatenated activations.\n",
    "    all_labels (np.ndarray): Corresponding labels extracted from filenames.\n",
    "    \"\"\"\n",
    "\n",
    "    # set activation directory\n",
    "    #acts_dir = f'{git_dir}/demo_data/acts/resnet50'\n",
    "\n",
    "    #glob all activation files\n",
    "    act_files = glob(f'{acts_dir}/*.npy')\n",
    "\n",
    "    #loop through activation files and concatenate them\n",
    "    # also get labels from filenames\n",
    "    all_acts = []\n",
    "    all_labels = []\n",
    "    for act_file in act_files:\n",
    "        acts = np.load(act_file)\n",
    "        label = os.path.basename(act_file).split('_')[1]  # assuming label is the second part of filename\n",
    "        n_samples = acts.shape[0]\n",
    "        \n",
    "        all_acts.append(acts)\n",
    "        all_labels.extend([label] * n_samples)\n",
    "\n",
    "    all_acts = np.vstack(all_acts)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return all_acts, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1402b7e",
   "metadata": {},
   "source": [
    "### Common classifiers\n",
    "- Decision trees: Basically a set of if-then rules. If X > 5 and Y < 3, then class A, else class B.\n",
    "    - Good when features have non-linear relationships with the class labels or when there aren't many features (<1000). Can overfit if not pruned.\n",
    "    - Random forests: An ensemble of decision trees trained on random subsets of the data and features. Reduces overfitting compared to a single decision tree.    \n",
    "\n",
    "- Support vector machines (SVMs): Find the hyperplane (i.e., line) between the data that best separates classes in feature space.\n",
    "    - Good for smaller datasets with clear distinction between classes. Can use kernel functions to handle non-linear boundaries.\n",
    "\n",
    "- K-nearest neighbors (k-NN): Classify new sample based on which k training samples are closest to it in the feature space. \n",
    "    - Good for smaller datasets that may not have clear borders, but do have clusters.\n",
    "    - nearest centroid: A special case of k-NN where k = 1 and the centroid (mean) of each class is used as the neighbor.\n",
    "\n",
    "- Logistic regression: Models the probability of a sample belonging to a class using a logistic function.\n",
    "    - Good for  datasets with linear relationships between features and class labels.\n",
    "    - Ridge regression: A type of linear regression that weights the features and penalizes large coefficients to prevent overfitting.\n",
    "\n",
    "**Note: these are oversimplifications of each method**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bc8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'KNN'  # options: 'SVM', 'Ridge', 'NB', 'KNN', 'logistic', 'NC'\n",
    "\n",
    "if classifier == 'SVM':\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "elif classifier == 'Ridge':\n",
    "    clf = make_pipeline(StandardScaler(), RidgeClassifierCV())\n",
    "elif classifier == 'NB':\n",
    "    clf = make_pipeline(StandardScaler(), GaussianNB())\n",
    "elif classifier == 'KNN':\n",
    "    clf = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "elif classifier == 'logistic':\n",
    "    clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "elif classifier == 'NC':\n",
    "    clf = make_pipeline(StandardScaler(), NearestCentroid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1c6a4",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "Fit the model on a subset of the data (training set) and evaluate performance on held-out data (validation set). - - Repeat multiple times with different splits to get an average performance metric. \n",
    "\n",
    "**Common approaches**\n",
    "- Leave-one-out cross-validation: Train on N-1 and test on the 1 left out. Repeat for all samples. Good for small datasets (e.g., runs of fMRI data). \n",
    "- K-fold cross-validation: Split data into K equal parts. Train on K-N parts and test on the N left out. Repeat K times. Good for larger datasets. (e.g., train on 80% test on 20%)\n",
    "    - Stratified k-fold: Like k-fold but ensures each fold has the same class distribution as the overall dataset. Good for imbalanced classes. (e.g., samples evenly from each category depending on their proportion in the dataset.)\n",
    "- Shuffle-split: Randomly split data into training and test sets multiple times. Good for large datasets where k-fold may be computationally expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca25b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 mean accuracy 0.0008333333333333333\n",
      "convnext mean accuracy 0.9822222222222223\n",
      "vit mean accuracy 0.7311111111111112\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train and test on same dataset with cross-validation\n",
    "'''\n",
    "\n",
    "models = ['resnet50', 'convnext', 'vit']\n",
    "#create dataframe to store results for each model\n",
    "results = pd.DataFrame(columns=['model', 'acc'])\n",
    "\n",
    "for model in models:\n",
    "    all_acts, all_labels = concat_acts(f'{git_dir}/demo_data/acts/{model}')\n",
    "\n",
    "    # decode images using stratified shuffle split and SVC\n",
    "    n_splits = 100\n",
    "    test_size = 0.2\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in sss.split(all_acts, all_labels):\n",
    "        X_train, X_test = all_acts[train_index], all_acts[test_index]\n",
    "        y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "        \n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    print(f'{model} mean accuracy {np.mean(accuracies)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4a98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext test accuracy on natural: 0.9555555555555556\n",
      "convnext test accuracy on scramble: 0.8777777777777778\n",
      "convnext test accuracy on shape: 0.46111111111111114\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train on one dataset and test on another\n",
    "'''\n",
    "train_data_name = ''\n",
    "test_data_names= ['natural','scramble','shape']\n",
    "\n",
    "models = ['convnext']\n",
    "for model in models:\n",
    "    train_acts, train_labels = concat_acts(f'{git_dir}/demo_data/acts/{model}{train_data_name}')\n",
    "    for test_data_name in test_data_names:\n",
    "        test_acts, test_labels = concat_acts(f'{git_dir}/demo_data/acts/{model}_{test_data_name}')\n",
    "        clf.fit(train_acts, train_labels)\n",
    "        acc = clf.score(test_acts, test_labels)\n",
    "        print(f'{model} test accuracy on {test_data_name}: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73938078",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c612593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
